; ModuleID = '/home/nrb74/ece5775/ECE5775_Final_Proj/matmult/1-mat_mult.prj/solution1/.autopilot/db/a.o.2.bc'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@matmult_str = internal unnamed_addr constant [8 x i8] c"matmult\00"
@llvm_global_ctors_1 = appending global [1 x void ()*] [void ()* @_GLOBAL__I_a]
@llvm_global_ctors_0 = appending global [1 x i32] [i32 65535]
@p_str1 = private unnamed_addr constant [1 x i8] zeroinitializer, align 1
@p_str = private unnamed_addr constant [16 x i8] c"LOOP_MAT_MULT_0\00", align 1

define void @matmult([10000 x float]* %a, [10000 x float]* %b, [100 x float]* %out_r) nounwind uwtable {
  call void (...)* @_ssdm_op_SpecBitsMap([10000 x float]* %a) nounwind, !map !14
  call void (...)* @_ssdm_op_SpecBitsMap([10000 x float]* %b) nounwind, !map !20
  call void (...)* @_ssdm_op_SpecBitsMap([100 x float]* %out_r) nounwind, !map !24
  call void (...)* @_ssdm_op_SpecTopModule([8 x i8]* @matmult_str) nounwind
  br label %1

; <label>:1                                       ; preds = %2, %0
  %i = phi i7 [ 0, %0 ], [ %i_1, %2 ]
  %phi_mul = phi i14 [ 0, %0 ], [ %next_mul, %2 ]
  %phi_mul_cast = zext i14 %phi_mul to i64
  %exitcond1 = icmp eq i7 %i, -28
  %i_1 = add i7 %i, 1
  br i1 %exitcond1, label %3, label %2

; <label>:2                                       ; preds = %1
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 100, i64 100, i64 100) nounwind
  call void (...)* @_ssdm_op_SpecLoopName([16 x i8]* @p_str) nounwind
  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([16 x i8]* @p_str) nounwind
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str1) nounwind
  %tmp = zext i7 %i to i64
  %next_mul = add i14 %phi_mul, 100
  %a_addr = getelementptr [10000 x float]* %a, i64 0, i64 %phi_mul_cast
  %tmp_3 = or i14 %phi_mul, 1
  %tmp_3_cast = zext i14 %tmp_3 to i64
  %a_addr_1 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_3_cast
  %tmp_6 = or i14 %phi_mul, 2
  %tmp_6_cast = zext i14 %tmp_6 to i64
  %a_addr_2 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_6_cast
  %tmp_7 = or i14 %phi_mul, 3
  %tmp_7_cast = zext i14 %tmp_7 to i64
  %a_addr_3 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_7_cast
  %tmp_8 = add i14 %phi_mul, 4
  %tmp_8_cast = zext i14 %tmp_8 to i64
  %a_addr_4 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_8_cast
  %tmp_9 = add i14 %phi_mul, 5
  %tmp_9_cast = zext i14 %tmp_9 to i64
  %a_addr_5 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_9_cast
  %tmp_s = add i14 %phi_mul, 6
  %tmp_10_cast = zext i14 %tmp_s to i64
  %a_addr_6 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_10_cast
  %tmp_2 = add i14 %phi_mul, 7
  %tmp_11_cast = zext i14 %tmp_2 to i64
  %a_addr_7 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_11_cast
  %tmp_10 = add i14 %phi_mul, 8
  %tmp_12_cast = zext i14 %tmp_10 to i64
  %a_addr_8 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_12_cast
  %tmp_11 = add i14 %phi_mul, 9
  %tmp_13_cast = zext i14 %tmp_11 to i64
  %a_addr_9 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_13_cast
  %tmp_12 = add i14 %phi_mul, 10
  %tmp_14_cast = zext i14 %tmp_12 to i64
  %a_addr_10 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_14_cast
  %tmp_13 = add i14 %phi_mul, 11
  %tmp_15_cast = zext i14 %tmp_13 to i64
  %a_addr_11 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_15_cast
  %tmp_14 = add i14 %phi_mul, 12
  %tmp_16_cast = zext i14 %tmp_14 to i64
  %a_addr_12 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_16_cast
  %tmp_15 = add i14 %phi_mul, 13
  %tmp_17_cast = zext i14 %tmp_15 to i64
  %a_addr_13 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_17_cast
  %tmp_16 = add i14 %phi_mul, 14
  %tmp_18_cast = zext i14 %tmp_16 to i64
  %a_addr_14 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_18_cast
  %tmp_17 = add i14 %phi_mul, 15
  %tmp_19_cast = zext i14 %tmp_17 to i64
  %a_addr_15 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_19_cast
  %tmp_18 = add i14 %phi_mul, 16
  %tmp_20_cast = zext i14 %tmp_18 to i64
  %a_addr_16 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_20_cast
  %tmp_19 = add i14 %phi_mul, 17
  %tmp_21_cast = zext i14 %tmp_19 to i64
  %a_addr_17 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_21_cast
  %tmp_20 = add i14 %phi_mul, 18
  %tmp_22_cast = zext i14 %tmp_20 to i64
  %a_addr_18 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_22_cast
  %tmp_21 = add i14 %phi_mul, 19
  %tmp_23_cast = zext i14 %tmp_21 to i64
  %a_addr_19 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_23_cast
  %tmp_22 = add i14 %phi_mul, 20
  %tmp_24_cast = zext i14 %tmp_22 to i64
  %a_addr_20 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_24_cast
  %tmp_23 = add i14 %phi_mul, 21
  %tmp_25_cast = zext i14 %tmp_23 to i64
  %a_addr_21 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_25_cast
  %tmp_24 = add i14 %phi_mul, 22
  %tmp_26_cast = zext i14 %tmp_24 to i64
  %a_addr_22 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_26_cast
  %tmp_25 = add i14 %phi_mul, 23
  %tmp_27_cast = zext i14 %tmp_25 to i64
  %a_addr_23 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_27_cast
  %tmp_26 = add i14 %phi_mul, 24
  %tmp_28_cast = zext i14 %tmp_26 to i64
  %a_addr_24 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_28_cast
  %tmp_27 = add i14 %phi_mul, 25
  %tmp_29_cast = zext i14 %tmp_27 to i64
  %a_addr_25 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_29_cast
  %tmp_28 = add i14 %phi_mul, 26
  %tmp_30_cast = zext i14 %tmp_28 to i64
  %a_addr_26 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_30_cast
  %tmp_29 = add i14 %phi_mul, 27
  %tmp_31_cast = zext i14 %tmp_29 to i64
  %a_addr_27 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_31_cast
  %tmp_30 = add i14 %phi_mul, 28
  %tmp_32_cast = zext i14 %tmp_30 to i64
  %a_addr_28 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_32_cast
  %tmp_31 = add i14 %phi_mul, 29
  %tmp_33_cast = zext i14 %tmp_31 to i64
  %a_addr_29 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_33_cast
  %tmp_32 = add i14 %phi_mul, 30
  %tmp_34_cast = zext i14 %tmp_32 to i64
  %a_addr_30 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_34_cast
  %tmp_33 = add i14 %phi_mul, 31
  %tmp_35_cast = zext i14 %tmp_33 to i64
  %a_addr_31 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_35_cast
  %tmp_34 = add i14 %phi_mul, 32
  %tmp_36_cast = zext i14 %tmp_34 to i64
  %a_addr_32 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_36_cast
  %tmp_35 = add i14 %phi_mul, 33
  %tmp_37_cast = zext i14 %tmp_35 to i64
  %a_addr_33 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_37_cast
  %tmp_36 = add i14 %phi_mul, 34
  %tmp_38_cast = zext i14 %tmp_36 to i64
  %a_addr_34 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_38_cast
  %tmp_37 = add i14 %phi_mul, 35
  %tmp_39_cast = zext i14 %tmp_37 to i64
  %a_addr_35 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_39_cast
  %tmp_38 = add i14 %phi_mul, 36
  %tmp_40_cast = zext i14 %tmp_38 to i64
  %a_addr_36 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_40_cast
  %tmp_39 = add i14 %phi_mul, 37
  %tmp_41_cast = zext i14 %tmp_39 to i64
  %a_addr_37 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_41_cast
  %tmp_40 = add i14 %phi_mul, 38
  %tmp_42_cast = zext i14 %tmp_40 to i64
  %a_addr_38 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_42_cast
  %tmp_41 = add i14 %phi_mul, 39
  %tmp_43_cast = zext i14 %tmp_41 to i64
  %a_addr_39 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_43_cast
  %tmp_42 = add i14 %phi_mul, 40
  %tmp_44_cast = zext i14 %tmp_42 to i64
  %a_addr_40 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_44_cast
  %tmp_43 = add i14 %phi_mul, 41
  %tmp_45_cast = zext i14 %tmp_43 to i64
  %a_addr_41 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_45_cast
  %tmp_44 = add i14 %phi_mul, 42
  %tmp_46_cast = zext i14 %tmp_44 to i64
  %a_addr_42 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_46_cast
  %tmp_45 = add i14 %phi_mul, 43
  %tmp_47_cast = zext i14 %tmp_45 to i64
  %a_addr_43 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_47_cast
  %tmp_46 = add i14 %phi_mul, 44
  %tmp_48_cast = zext i14 %tmp_46 to i64
  %a_addr_44 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_48_cast
  %tmp_47 = add i14 %phi_mul, 45
  %tmp_49_cast = zext i14 %tmp_47 to i64
  %a_addr_45 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_49_cast
  %tmp_48 = add i14 %phi_mul, 46
  %tmp_50_cast = zext i14 %tmp_48 to i64
  %a_addr_46 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_50_cast
  %tmp_49 = add i14 %phi_mul, 47
  %tmp_51_cast = zext i14 %tmp_49 to i64
  %a_addr_47 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_51_cast
  %tmp_50 = add i14 %phi_mul, 48
  %tmp_52_cast = zext i14 %tmp_50 to i64
  %a_addr_48 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_52_cast
  %tmp_51 = add i14 %phi_mul, 49
  %tmp_53_cast = zext i14 %tmp_51 to i64
  %a_addr_49 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_53_cast
  %tmp_52 = add i14 %phi_mul, 50
  %tmp_54_cast = zext i14 %tmp_52 to i64
  %a_addr_50 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_54_cast
  %tmp_53 = add i14 %phi_mul, 51
  %tmp_55_cast = zext i14 %tmp_53 to i64
  %a_addr_51 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_55_cast
  %tmp_54 = add i14 %phi_mul, 52
  %tmp_56_cast = zext i14 %tmp_54 to i64
  %a_addr_52 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_56_cast
  %tmp_55 = add i14 %phi_mul, 53
  %tmp_57_cast = zext i14 %tmp_55 to i64
  %a_addr_53 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_57_cast
  %tmp_56 = add i14 %phi_mul, 54
  %tmp_58_cast = zext i14 %tmp_56 to i64
  %a_addr_54 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_58_cast
  %tmp_57 = add i14 %phi_mul, 55
  %tmp_59_cast = zext i14 %tmp_57 to i64
  %a_addr_55 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_59_cast
  %tmp_58 = add i14 %phi_mul, 56
  %tmp_60_cast = zext i14 %tmp_58 to i64
  %a_addr_56 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_60_cast
  %tmp_59 = add i14 %phi_mul, 57
  %tmp_61_cast = zext i14 %tmp_59 to i64
  %a_addr_57 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_61_cast
  %tmp_60 = add i14 %phi_mul, 58
  %tmp_62_cast = zext i14 %tmp_60 to i64
  %a_addr_58 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_62_cast
  %tmp_61 = add i14 %phi_mul, 59
  %tmp_63_cast = zext i14 %tmp_61 to i64
  %a_addr_59 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_63_cast
  %tmp_62 = add i14 %phi_mul, 60
  %tmp_64_cast = zext i14 %tmp_62 to i64
  %a_addr_60 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_64_cast
  %tmp_63 = add i14 %phi_mul, 61
  %tmp_65_cast = zext i14 %tmp_63 to i64
  %a_addr_61 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_65_cast
  %tmp_64 = add i14 %phi_mul, 62
  %tmp_66_cast = zext i14 %tmp_64 to i64
  %a_addr_62 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_66_cast
  %tmp_65 = add i14 %phi_mul, 63
  %tmp_67_cast = zext i14 %tmp_65 to i64
  %a_addr_63 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_67_cast
  %tmp_66 = add i14 %phi_mul, 64
  %tmp_68_cast = zext i14 %tmp_66 to i64
  %a_addr_64 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_68_cast
  %tmp_67 = add i14 %phi_mul, 65
  %tmp_69_cast = zext i14 %tmp_67 to i64
  %a_addr_65 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_69_cast
  %tmp_68 = add i14 %phi_mul, 66
  %tmp_70_cast = zext i14 %tmp_68 to i64
  %a_addr_66 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_70_cast
  %tmp_69 = add i14 %phi_mul, 67
  %tmp_71_cast = zext i14 %tmp_69 to i64
  %a_addr_67 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_71_cast
  %tmp_70 = add i14 %phi_mul, 68
  %tmp_72_cast = zext i14 %tmp_70 to i64
  %a_addr_68 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_72_cast
  %tmp_71 = add i14 %phi_mul, 69
  %tmp_73_cast = zext i14 %tmp_71 to i64
  %a_addr_69 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_73_cast
  %tmp_72 = add i14 %phi_mul, 70
  %tmp_74_cast = zext i14 %tmp_72 to i64
  %a_addr_70 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_74_cast
  %tmp_73 = add i14 %phi_mul, 71
  %tmp_75_cast = zext i14 %tmp_73 to i64
  %a_addr_71 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_75_cast
  %tmp_74 = add i14 %phi_mul, 72
  %tmp_76_cast = zext i14 %tmp_74 to i64
  %a_addr_72 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_76_cast
  %tmp_75 = add i14 %phi_mul, 73
  %tmp_77_cast = zext i14 %tmp_75 to i64
  %a_addr_73 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_77_cast
  %tmp_76 = add i14 %phi_mul, 74
  %tmp_78_cast = zext i14 %tmp_76 to i64
  %a_addr_74 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_78_cast
  %tmp_77 = add i14 %phi_mul, 75
  %tmp_79_cast = zext i14 %tmp_77 to i64
  %a_addr_75 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_79_cast
  %tmp_78 = add i14 %phi_mul, 76
  %tmp_80_cast = zext i14 %tmp_78 to i64
  %a_addr_76 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_80_cast
  %tmp_79 = add i14 %phi_mul, 77
  %tmp_81_cast = zext i14 %tmp_79 to i64
  %a_addr_77 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_81_cast
  %tmp_80 = add i14 %phi_mul, 78
  %tmp_82_cast = zext i14 %tmp_80 to i64
  %a_addr_78 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_82_cast
  %tmp_81 = add i14 %phi_mul, 79
  %tmp_83_cast = zext i14 %tmp_81 to i64
  %a_addr_79 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_83_cast
  %tmp_82 = add i14 %phi_mul, 80
  %tmp_84_cast = zext i14 %tmp_82 to i64
  %a_addr_80 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_84_cast
  %tmp_83 = add i14 %phi_mul, 81
  %tmp_85_cast = zext i14 %tmp_83 to i64
  %a_addr_81 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_85_cast
  %tmp_84 = add i14 %phi_mul, 82
  %tmp_86_cast = zext i14 %tmp_84 to i64
  %a_addr_82 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_86_cast
  %tmp_85 = add i14 %phi_mul, 83
  %tmp_87_cast = zext i14 %tmp_85 to i64
  %a_addr_83 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_87_cast
  %tmp_86 = add i14 %phi_mul, 84
  %tmp_88_cast = zext i14 %tmp_86 to i64
  %a_addr_84 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_88_cast
  %tmp_87 = add i14 %phi_mul, 85
  %tmp_89_cast = zext i14 %tmp_87 to i64
  %a_addr_85 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_89_cast
  %tmp_88 = add i14 %phi_mul, 86
  %tmp_90_cast = zext i14 %tmp_88 to i64
  %a_addr_86 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_90_cast
  %tmp_89 = add i14 %phi_mul, 87
  %tmp_91_cast = zext i14 %tmp_89 to i64
  %a_addr_87 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_91_cast
  %tmp_90 = add i14 %phi_mul, 88
  %tmp_92_cast = zext i14 %tmp_90 to i64
  %a_addr_88 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_92_cast
  %tmp_91 = add i14 %phi_mul, 89
  %tmp_93_cast = zext i14 %tmp_91 to i64
  %a_addr_89 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_93_cast
  %tmp_92 = add i14 %phi_mul, 90
  %tmp_94_cast = zext i14 %tmp_92 to i64
  %a_addr_90 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_94_cast
  %tmp_93 = add i14 %phi_mul, 91
  %tmp_95_cast = zext i14 %tmp_93 to i64
  %a_addr_91 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_95_cast
  %tmp_94 = add i14 %phi_mul, 92
  %tmp_96_cast = zext i14 %tmp_94 to i64
  %a_addr_92 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_96_cast
  %tmp_95 = add i14 %phi_mul, 93
  %tmp_97_cast = zext i14 %tmp_95 to i64
  %a_addr_93 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_97_cast
  %tmp_96 = add i14 %phi_mul, 94
  %tmp_98_cast = zext i14 %tmp_96 to i64
  %a_addr_94 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_98_cast
  %tmp_97 = add i14 %phi_mul, 95
  %tmp_99_cast = zext i14 %tmp_97 to i64
  %a_addr_95 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_99_cast
  %tmp_98 = add i14 %phi_mul, 96
  %tmp_100_cast = zext i14 %tmp_98 to i64
  %a_addr_96 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_100_cast
  %tmp_99 = add i14 %phi_mul, 97
  %tmp_101_cast = zext i14 %tmp_99 to i64
  %a_addr_97 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_101_cast
  %tmp_100 = add i14 %phi_mul, 98
  %tmp_102_cast = zext i14 %tmp_100 to i64
  %a_addr_98 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_102_cast
  %tmp_101 = add i14 %phi_mul, 99
  %tmp_103_cast = zext i14 %tmp_101 to i64
  %a_addr_99 = getelementptr [10000 x float]* %a, i64 0, i64 %tmp_103_cast
  %b_addr = getelementptr [10000 x float]* %b, i64 0, i64 %phi_mul_cast
  %b_addr_1 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_3_cast
  %b_addr_2 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_6_cast
  %b_addr_3 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_7_cast
  %b_addr_4 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_8_cast
  %b_addr_5 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_9_cast
  %b_addr_6 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_10_cast
  %b_addr_7 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_11_cast
  %b_addr_8 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_12_cast
  %b_addr_9 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_13_cast
  %b_addr_10 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_14_cast
  %b_addr_11 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_15_cast
  %b_addr_12 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_16_cast
  %b_addr_13 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_17_cast
  %b_addr_14 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_18_cast
  %b_addr_15 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_19_cast
  %b_addr_16 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_20_cast
  %b_addr_17 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_21_cast
  %b_addr_18 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_22_cast
  %b_addr_19 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_23_cast
  %b_addr_20 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_24_cast
  %b_addr_21 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_25_cast
  %b_addr_22 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_26_cast
  %b_addr_23 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_27_cast
  %b_addr_24 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_28_cast
  %b_addr_25 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_29_cast
  %b_addr_26 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_30_cast
  %b_addr_27 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_31_cast
  %b_addr_28 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_32_cast
  %b_addr_29 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_33_cast
  %b_addr_30 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_34_cast
  %b_addr_31 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_35_cast
  %b_addr_32 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_36_cast
  %b_addr_33 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_37_cast
  %b_addr_34 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_38_cast
  %b_addr_35 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_39_cast
  %b_addr_36 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_40_cast
  %b_addr_37 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_41_cast
  %b_addr_38 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_42_cast
  %b_addr_39 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_43_cast
  %b_addr_40 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_44_cast
  %b_addr_41 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_45_cast
  %b_addr_42 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_46_cast
  %b_addr_43 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_47_cast
  %b_addr_44 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_48_cast
  %b_addr_45 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_49_cast
  %b_addr_46 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_50_cast
  %b_addr_47 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_51_cast
  %b_addr_48 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_52_cast
  %b_addr_49 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_53_cast
  %b_addr_50 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_54_cast
  %b_addr_51 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_55_cast
  %b_addr_52 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_56_cast
  %b_addr_53 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_57_cast
  %b_addr_54 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_58_cast
  %b_addr_55 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_59_cast
  %b_addr_56 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_60_cast
  %b_addr_57 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_61_cast
  %b_addr_58 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_62_cast
  %b_addr_59 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_63_cast
  %b_addr_60 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_64_cast
  %b_addr_61 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_65_cast
  %b_addr_62 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_66_cast
  %b_addr_63 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_67_cast
  %b_addr_64 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_68_cast
  %b_addr_65 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_69_cast
  %b_addr_66 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_70_cast
  %b_addr_67 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_71_cast
  %b_addr_68 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_72_cast
  %b_addr_69 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_73_cast
  %b_addr_70 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_74_cast
  %b_addr_71 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_75_cast
  %b_addr_72 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_76_cast
  %b_addr_73 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_77_cast
  %b_addr_74 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_78_cast
  %b_addr_75 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_79_cast
  %b_addr_76 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_80_cast
  %b_addr_77 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_81_cast
  %b_addr_78 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_82_cast
  %b_addr_79 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_83_cast
  %b_addr_80 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_84_cast
  %b_addr_81 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_85_cast
  %b_addr_82 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_86_cast
  %b_addr_83 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_87_cast
  %b_addr_84 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_88_cast
  %b_addr_85 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_89_cast
  %b_addr_86 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_90_cast
  %b_addr_87 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_91_cast
  %b_addr_88 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_92_cast
  %b_addr_89 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_93_cast
  %b_addr_90 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_94_cast
  %b_addr_91 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_95_cast
  %b_addr_92 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_96_cast
  %b_addr_93 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_97_cast
  %b_addr_94 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_98_cast
  %b_addr_95 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_99_cast
  %b_addr_96 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_100_cast
  %b_addr_97 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_101_cast
  %b_addr_98 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_102_cast
  %b_addr_99 = getelementptr [10000 x float]* %b, i64 0, i64 %tmp_103_cast
  %out_addr = getelementptr [100 x float]* %out_r, i64 0, i64 %tmp
  %a_load = load float* %a_addr, align 4
  %b_load = load float* %b_addr, align 4
  %tmp_4 = fmul float %a_load, %b_load
  %tmp_5 = fadd float %tmp_4, 0.000000e+00
  %a_load_1 = load float* %a_addr_1, align 4
  %b_load_1 = load float* %b_addr_1, align 4
  %tmp_4_1 = fmul float %a_load_1, %b_load_1
  %tmp_5_1 = fadd float %tmp_5, %tmp_4_1
  %a_load_2 = load float* %a_addr_2, align 4
  %b_load_2 = load float* %b_addr_2, align 4
  %tmp_4_2 = fmul float %a_load_2, %b_load_2
  %tmp_5_2 = fadd float %tmp_5_1, %tmp_4_2
  %a_load_3 = load float* %a_addr_3, align 4
  %b_load_3 = load float* %b_addr_3, align 4
  %tmp_4_3 = fmul float %a_load_3, %b_load_3
  %tmp_5_3 = fadd float %tmp_5_2, %tmp_4_3
  %a_load_4 = load float* %a_addr_4, align 4
  %b_load_4 = load float* %b_addr_4, align 4
  %tmp_4_4 = fmul float %a_load_4, %b_load_4
  %tmp_5_4 = fadd float %tmp_5_3, %tmp_4_4
  %a_load_5 = load float* %a_addr_5, align 4
  %b_load_5 = load float* %b_addr_5, align 4
  %tmp_4_5 = fmul float %a_load_5, %b_load_5
  %tmp_5_5 = fadd float %tmp_5_4, %tmp_4_5
  %a_load_6 = load float* %a_addr_6, align 4
  %b_load_6 = load float* %b_addr_6, align 4
  %tmp_4_6 = fmul float %a_load_6, %b_load_6
  %tmp_5_6 = fadd float %tmp_5_5, %tmp_4_6
  %a_load_7 = load float* %a_addr_7, align 4
  %b_load_7 = load float* %b_addr_7, align 4
  %tmp_4_7 = fmul float %a_load_7, %b_load_7
  %tmp_5_7 = fadd float %tmp_5_6, %tmp_4_7
  %a_load_8 = load float* %a_addr_8, align 4
  %b_load_8 = load float* %b_addr_8, align 4
  %tmp_4_8 = fmul float %a_load_8, %b_load_8
  %tmp_5_8 = fadd float %tmp_5_7, %tmp_4_8
  %a_load_9 = load float* %a_addr_9, align 4
  %b_load_9 = load float* %b_addr_9, align 4
  %tmp_4_9 = fmul float %a_load_9, %b_load_9
  %tmp_5_9 = fadd float %tmp_5_8, %tmp_4_9
  %a_load_10 = load float* %a_addr_10, align 4
  %b_load_10 = load float* %b_addr_10, align 4
  %tmp_4_s = fmul float %a_load_10, %b_load_10
  %tmp_5_s = fadd float %tmp_5_9, %tmp_4_s
  %a_load_11 = load float* %a_addr_11, align 4
  %b_load_11 = load float* %b_addr_11, align 4
  %tmp_4_10 = fmul float %a_load_11, %b_load_11
  %tmp_5_10 = fadd float %tmp_5_s, %tmp_4_10
  %a_load_12 = load float* %a_addr_12, align 4
  %b_load_12 = load float* %b_addr_12, align 4
  %tmp_4_11 = fmul float %a_load_12, %b_load_12
  %tmp_5_11 = fadd float %tmp_5_10, %tmp_4_11
  %a_load_13 = load float* %a_addr_13, align 4
  %b_load_13 = load float* %b_addr_13, align 4
  %tmp_4_12 = fmul float %a_load_13, %b_load_13
  %tmp_5_12 = fadd float %tmp_5_11, %tmp_4_12
  %a_load_14 = load float* %a_addr_14, align 4
  %b_load_14 = load float* %b_addr_14, align 4
  %tmp_4_13 = fmul float %a_load_14, %b_load_14
  %tmp_5_13 = fadd float %tmp_5_12, %tmp_4_13
  %a_load_15 = load float* %a_addr_15, align 4
  %b_load_15 = load float* %b_addr_15, align 4
  %tmp_4_14 = fmul float %a_load_15, %b_load_15
  %tmp_5_14 = fadd float %tmp_5_13, %tmp_4_14
  %a_load_16 = load float* %a_addr_16, align 4
  %b_load_16 = load float* %b_addr_16, align 4
  %tmp_4_15 = fmul float %a_load_16, %b_load_16
  %tmp_5_15 = fadd float %tmp_5_14, %tmp_4_15
  %a_load_17 = load float* %a_addr_17, align 4
  %b_load_17 = load float* %b_addr_17, align 4
  %tmp_4_16 = fmul float %a_load_17, %b_load_17
  %tmp_5_16 = fadd float %tmp_5_15, %tmp_4_16
  %a_load_18 = load float* %a_addr_18, align 4
  %b_load_18 = load float* %b_addr_18, align 4
  %tmp_4_17 = fmul float %a_load_18, %b_load_18
  %tmp_5_17 = fadd float %tmp_5_16, %tmp_4_17
  %a_load_19 = load float* %a_addr_19, align 4
  %b_load_19 = load float* %b_addr_19, align 4
  %tmp_4_18 = fmul float %a_load_19, %b_load_19
  %tmp_5_18 = fadd float %tmp_5_17, %tmp_4_18
  %a_load_20 = load float* %a_addr_20, align 4
  %b_load_20 = load float* %b_addr_20, align 4
  %tmp_4_19 = fmul float %a_load_20, %b_load_20
  %tmp_5_19 = fadd float %tmp_5_18, %tmp_4_19
  %a_load_21 = load float* %a_addr_21, align 4
  %b_load_21 = load float* %b_addr_21, align 4
  %tmp_4_20 = fmul float %a_load_21, %b_load_21
  %tmp_5_20 = fadd float %tmp_5_19, %tmp_4_20
  %a_load_22 = load float* %a_addr_22, align 4
  %b_load_22 = load float* %b_addr_22, align 4
  %tmp_4_21 = fmul float %a_load_22, %b_load_22
  %tmp_5_21 = fadd float %tmp_5_20, %tmp_4_21
  %a_load_23 = load float* %a_addr_23, align 4
  %b_load_23 = load float* %b_addr_23, align 4
  %tmp_4_22 = fmul float %a_load_23, %b_load_23
  %tmp_5_22 = fadd float %tmp_5_21, %tmp_4_22
  %a_load_24 = load float* %a_addr_24, align 4
  %b_load_24 = load float* %b_addr_24, align 4
  %tmp_4_23 = fmul float %a_load_24, %b_load_24
  %tmp_5_23 = fadd float %tmp_5_22, %tmp_4_23
  %a_load_25 = load float* %a_addr_25, align 4
  %b_load_25 = load float* %b_addr_25, align 4
  %tmp_4_24 = fmul float %a_load_25, %b_load_25
  %tmp_5_24 = fadd float %tmp_5_23, %tmp_4_24
  %a_load_26 = load float* %a_addr_26, align 4
  %b_load_26 = load float* %b_addr_26, align 4
  %tmp_4_25 = fmul float %a_load_26, %b_load_26
  %tmp_5_25 = fadd float %tmp_5_24, %tmp_4_25
  %a_load_27 = load float* %a_addr_27, align 4
  %b_load_27 = load float* %b_addr_27, align 4
  %tmp_4_26 = fmul float %a_load_27, %b_load_27
  %tmp_5_26 = fadd float %tmp_5_25, %tmp_4_26
  %a_load_28 = load float* %a_addr_28, align 4
  %b_load_28 = load float* %b_addr_28, align 4
  %tmp_4_27 = fmul float %a_load_28, %b_load_28
  %tmp_5_27 = fadd float %tmp_5_26, %tmp_4_27
  %a_load_29 = load float* %a_addr_29, align 4
  %b_load_29 = load float* %b_addr_29, align 4
  %tmp_4_28 = fmul float %a_load_29, %b_load_29
  %tmp_5_28 = fadd float %tmp_5_27, %tmp_4_28
  %a_load_30 = load float* %a_addr_30, align 4
  %b_load_30 = load float* %b_addr_30, align 4
  %tmp_4_29 = fmul float %a_load_30, %b_load_30
  %tmp_5_29 = fadd float %tmp_5_28, %tmp_4_29
  %a_load_31 = load float* %a_addr_31, align 4
  %b_load_31 = load float* %b_addr_31, align 4
  %tmp_4_30 = fmul float %a_load_31, %b_load_31
  %tmp_5_30 = fadd float %tmp_5_29, %tmp_4_30
  %a_load_32 = load float* %a_addr_32, align 4
  %b_load_32 = load float* %b_addr_32, align 4
  %tmp_4_31 = fmul float %a_load_32, %b_load_32
  %tmp_5_31 = fadd float %tmp_5_30, %tmp_4_31
  %a_load_33 = load float* %a_addr_33, align 4
  %b_load_33 = load float* %b_addr_33, align 4
  %tmp_4_32 = fmul float %a_load_33, %b_load_33
  %tmp_5_32 = fadd float %tmp_5_31, %tmp_4_32
  %a_load_34 = load float* %a_addr_34, align 4
  %b_load_34 = load float* %b_addr_34, align 4
  %tmp_4_33 = fmul float %a_load_34, %b_load_34
  %tmp_5_33 = fadd float %tmp_5_32, %tmp_4_33
  %a_load_35 = load float* %a_addr_35, align 4
  %b_load_35 = load float* %b_addr_35, align 4
  %tmp_4_34 = fmul float %a_load_35, %b_load_35
  %tmp_5_34 = fadd float %tmp_5_33, %tmp_4_34
  %a_load_36 = load float* %a_addr_36, align 4
  %b_load_36 = load float* %b_addr_36, align 4
  %tmp_4_35 = fmul float %a_load_36, %b_load_36
  %tmp_5_35 = fadd float %tmp_5_34, %tmp_4_35
  %a_load_37 = load float* %a_addr_37, align 4
  %b_load_37 = load float* %b_addr_37, align 4
  %tmp_4_36 = fmul float %a_load_37, %b_load_37
  %tmp_5_36 = fadd float %tmp_5_35, %tmp_4_36
  %a_load_38 = load float* %a_addr_38, align 4
  %b_load_38 = load float* %b_addr_38, align 4
  %tmp_4_37 = fmul float %a_load_38, %b_load_38
  %tmp_5_37 = fadd float %tmp_5_36, %tmp_4_37
  %a_load_39 = load float* %a_addr_39, align 4
  %b_load_39 = load float* %b_addr_39, align 4
  %tmp_4_38 = fmul float %a_load_39, %b_load_39
  %tmp_5_38 = fadd float %tmp_5_37, %tmp_4_38
  %a_load_40 = load float* %a_addr_40, align 4
  %b_load_40 = load float* %b_addr_40, align 4
  %tmp_4_39 = fmul float %a_load_40, %b_load_40
  %tmp_5_39 = fadd float %tmp_5_38, %tmp_4_39
  %a_load_41 = load float* %a_addr_41, align 4
  %b_load_41 = load float* %b_addr_41, align 4
  %tmp_4_40 = fmul float %a_load_41, %b_load_41
  %tmp_5_40 = fadd float %tmp_5_39, %tmp_4_40
  %a_load_42 = load float* %a_addr_42, align 4
  %b_load_42 = load float* %b_addr_42, align 4
  %tmp_4_41 = fmul float %a_load_42, %b_load_42
  %tmp_5_41 = fadd float %tmp_5_40, %tmp_4_41
  %a_load_43 = load float* %a_addr_43, align 4
  %b_load_43 = load float* %b_addr_43, align 4
  %tmp_4_42 = fmul float %a_load_43, %b_load_43
  %tmp_5_42 = fadd float %tmp_5_41, %tmp_4_42
  %a_load_44 = load float* %a_addr_44, align 4
  %b_load_44 = load float* %b_addr_44, align 4
  %tmp_4_43 = fmul float %a_load_44, %b_load_44
  %tmp_5_43 = fadd float %tmp_5_42, %tmp_4_43
  %a_load_45 = load float* %a_addr_45, align 4
  %b_load_45 = load float* %b_addr_45, align 4
  %tmp_4_44 = fmul float %a_load_45, %b_load_45
  %tmp_5_44 = fadd float %tmp_5_43, %tmp_4_44
  %a_load_46 = load float* %a_addr_46, align 4
  %b_load_46 = load float* %b_addr_46, align 4
  %tmp_4_45 = fmul float %a_load_46, %b_load_46
  %tmp_5_45 = fadd float %tmp_5_44, %tmp_4_45
  %a_load_47 = load float* %a_addr_47, align 4
  %b_load_47 = load float* %b_addr_47, align 4
  %tmp_4_46 = fmul float %a_load_47, %b_load_47
  %tmp_5_46 = fadd float %tmp_5_45, %tmp_4_46
  %a_load_48 = load float* %a_addr_48, align 4
  %b_load_48 = load float* %b_addr_48, align 4
  %tmp_4_47 = fmul float %a_load_48, %b_load_48
  %tmp_5_47 = fadd float %tmp_5_46, %tmp_4_47
  %a_load_49 = load float* %a_addr_49, align 4
  %b_load_49 = load float* %b_addr_49, align 4
  %tmp_4_48 = fmul float %a_load_49, %b_load_49
  %tmp_5_48 = fadd float %tmp_5_47, %tmp_4_48
  %a_load_50 = load float* %a_addr_50, align 4
  %b_load_50 = load float* %b_addr_50, align 4
  %tmp_4_49 = fmul float %a_load_50, %b_load_50
  %tmp_5_49 = fadd float %tmp_5_48, %tmp_4_49
  %a_load_51 = load float* %a_addr_51, align 4
  %b_load_51 = load float* %b_addr_51, align 4
  %tmp_4_50 = fmul float %a_load_51, %b_load_51
  %tmp_5_50 = fadd float %tmp_5_49, %tmp_4_50
  %a_load_52 = load float* %a_addr_52, align 4
  %b_load_52 = load float* %b_addr_52, align 4
  %tmp_4_51 = fmul float %a_load_52, %b_load_52
  %tmp_5_51 = fadd float %tmp_5_50, %tmp_4_51
  %a_load_53 = load float* %a_addr_53, align 4
  %b_load_53 = load float* %b_addr_53, align 4
  %tmp_4_52 = fmul float %a_load_53, %b_load_53
  %tmp_5_52 = fadd float %tmp_5_51, %tmp_4_52
  %a_load_54 = load float* %a_addr_54, align 4
  %b_load_54 = load float* %b_addr_54, align 4
  %tmp_4_53 = fmul float %a_load_54, %b_load_54
  %tmp_5_53 = fadd float %tmp_5_52, %tmp_4_53
  %a_load_55 = load float* %a_addr_55, align 4
  %b_load_55 = load float* %b_addr_55, align 4
  %tmp_4_54 = fmul float %a_load_55, %b_load_55
  %tmp_5_54 = fadd float %tmp_5_53, %tmp_4_54
  %a_load_56 = load float* %a_addr_56, align 4
  %b_load_56 = load float* %b_addr_56, align 4
  %tmp_4_55 = fmul float %a_load_56, %b_load_56
  %tmp_5_55 = fadd float %tmp_5_54, %tmp_4_55
  %a_load_57 = load float* %a_addr_57, align 4
  %b_load_57 = load float* %b_addr_57, align 4
  %tmp_4_56 = fmul float %a_load_57, %b_load_57
  %tmp_5_56 = fadd float %tmp_5_55, %tmp_4_56
  %a_load_58 = load float* %a_addr_58, align 4
  %b_load_58 = load float* %b_addr_58, align 4
  %tmp_4_57 = fmul float %a_load_58, %b_load_58
  %tmp_5_57 = fadd float %tmp_5_56, %tmp_4_57
  %a_load_59 = load float* %a_addr_59, align 4
  %b_load_59 = load float* %b_addr_59, align 4
  %tmp_4_58 = fmul float %a_load_59, %b_load_59
  %tmp_5_58 = fadd float %tmp_5_57, %tmp_4_58
  %a_load_60 = load float* %a_addr_60, align 4
  %b_load_60 = load float* %b_addr_60, align 4
  %tmp_4_59 = fmul float %a_load_60, %b_load_60
  %tmp_5_59 = fadd float %tmp_5_58, %tmp_4_59
  %a_load_61 = load float* %a_addr_61, align 4
  %b_load_61 = load float* %b_addr_61, align 4
  %tmp_4_60 = fmul float %a_load_61, %b_load_61
  %tmp_5_60 = fadd float %tmp_5_59, %tmp_4_60
  %a_load_62 = load float* %a_addr_62, align 4
  %b_load_62 = load float* %b_addr_62, align 4
  %tmp_4_61 = fmul float %a_load_62, %b_load_62
  %tmp_5_61 = fadd float %tmp_5_60, %tmp_4_61
  %a_load_63 = load float* %a_addr_63, align 4
  %b_load_63 = load float* %b_addr_63, align 4
  %tmp_4_62 = fmul float %a_load_63, %b_load_63
  %tmp_5_62 = fadd float %tmp_5_61, %tmp_4_62
  %a_load_64 = load float* %a_addr_64, align 4
  %b_load_64 = load float* %b_addr_64, align 4
  %tmp_4_63 = fmul float %a_load_64, %b_load_64
  %tmp_5_63 = fadd float %tmp_5_62, %tmp_4_63
  %a_load_65 = load float* %a_addr_65, align 4
  %b_load_65 = load float* %b_addr_65, align 4
  %tmp_4_64 = fmul float %a_load_65, %b_load_65
  %tmp_5_64 = fadd float %tmp_5_63, %tmp_4_64
  %a_load_66 = load float* %a_addr_66, align 4
  %b_load_66 = load float* %b_addr_66, align 4
  %tmp_4_65 = fmul float %a_load_66, %b_load_66
  %tmp_5_65 = fadd float %tmp_5_64, %tmp_4_65
  %a_load_67 = load float* %a_addr_67, align 4
  %b_load_67 = load float* %b_addr_67, align 4
  %tmp_4_66 = fmul float %a_load_67, %b_load_67
  %tmp_5_66 = fadd float %tmp_5_65, %tmp_4_66
  %a_load_68 = load float* %a_addr_68, align 4
  %b_load_68 = load float* %b_addr_68, align 4
  %tmp_4_67 = fmul float %a_load_68, %b_load_68
  %tmp_5_67 = fadd float %tmp_5_66, %tmp_4_67
  %a_load_69 = load float* %a_addr_69, align 4
  %b_load_69 = load float* %b_addr_69, align 4
  %tmp_4_68 = fmul float %a_load_69, %b_load_69
  %tmp_5_68 = fadd float %tmp_5_67, %tmp_4_68
  %a_load_70 = load float* %a_addr_70, align 4
  %b_load_70 = load float* %b_addr_70, align 4
  %tmp_4_69 = fmul float %a_load_70, %b_load_70
  %tmp_5_69 = fadd float %tmp_5_68, %tmp_4_69
  %a_load_71 = load float* %a_addr_71, align 4
  %b_load_71 = load float* %b_addr_71, align 4
  %tmp_4_70 = fmul float %a_load_71, %b_load_71
  %tmp_5_70 = fadd float %tmp_5_69, %tmp_4_70
  %a_load_72 = load float* %a_addr_72, align 4
  %b_load_72 = load float* %b_addr_72, align 4
  %tmp_4_71 = fmul float %a_load_72, %b_load_72
  %tmp_5_71 = fadd float %tmp_5_70, %tmp_4_71
  %a_load_73 = load float* %a_addr_73, align 4
  %b_load_73 = load float* %b_addr_73, align 4
  %tmp_4_72 = fmul float %a_load_73, %b_load_73
  %tmp_5_72 = fadd float %tmp_5_71, %tmp_4_72
  %a_load_74 = load float* %a_addr_74, align 4
  %b_load_74 = load float* %b_addr_74, align 4
  %tmp_4_73 = fmul float %a_load_74, %b_load_74
  %tmp_5_73 = fadd float %tmp_5_72, %tmp_4_73
  %a_load_75 = load float* %a_addr_75, align 4
  %b_load_75 = load float* %b_addr_75, align 4
  %tmp_4_74 = fmul float %a_load_75, %b_load_75
  %tmp_5_74 = fadd float %tmp_5_73, %tmp_4_74
  %a_load_76 = load float* %a_addr_76, align 4
  %b_load_76 = load float* %b_addr_76, align 4
  %tmp_4_75 = fmul float %a_load_76, %b_load_76
  %tmp_5_75 = fadd float %tmp_5_74, %tmp_4_75
  %a_load_77 = load float* %a_addr_77, align 4
  %b_load_77 = load float* %b_addr_77, align 4
  %tmp_4_76 = fmul float %a_load_77, %b_load_77
  %tmp_5_76 = fadd float %tmp_5_75, %tmp_4_76
  %a_load_78 = load float* %a_addr_78, align 4
  %b_load_78 = load float* %b_addr_78, align 4
  %tmp_4_77 = fmul float %a_load_78, %b_load_78
  %tmp_5_77 = fadd float %tmp_5_76, %tmp_4_77
  %a_load_79 = load float* %a_addr_79, align 4
  %b_load_79 = load float* %b_addr_79, align 4
  %tmp_4_78 = fmul float %a_load_79, %b_load_79
  %tmp_5_78 = fadd float %tmp_5_77, %tmp_4_78
  %a_load_80 = load float* %a_addr_80, align 4
  %b_load_80 = load float* %b_addr_80, align 4
  %tmp_4_79 = fmul float %a_load_80, %b_load_80
  %tmp_5_79 = fadd float %tmp_5_78, %tmp_4_79
  %a_load_81 = load float* %a_addr_81, align 4
  %b_load_81 = load float* %b_addr_81, align 4
  %tmp_4_80 = fmul float %a_load_81, %b_load_81
  %tmp_5_80 = fadd float %tmp_5_79, %tmp_4_80
  %a_load_82 = load float* %a_addr_82, align 4
  %b_load_82 = load float* %b_addr_82, align 4
  %tmp_4_81 = fmul float %a_load_82, %b_load_82
  %tmp_5_81 = fadd float %tmp_5_80, %tmp_4_81
  %a_load_83 = load float* %a_addr_83, align 4
  %b_load_83 = load float* %b_addr_83, align 4
  %tmp_4_82 = fmul float %a_load_83, %b_load_83
  %tmp_5_82 = fadd float %tmp_5_81, %tmp_4_82
  %a_load_84 = load float* %a_addr_84, align 4
  %b_load_84 = load float* %b_addr_84, align 4
  %tmp_4_83 = fmul float %a_load_84, %b_load_84
  %tmp_5_83 = fadd float %tmp_5_82, %tmp_4_83
  %a_load_85 = load float* %a_addr_85, align 4
  %b_load_85 = load float* %b_addr_85, align 4
  %tmp_4_84 = fmul float %a_load_85, %b_load_85
  %tmp_5_84 = fadd float %tmp_5_83, %tmp_4_84
  %a_load_86 = load float* %a_addr_86, align 4
  %b_load_86 = load float* %b_addr_86, align 4
  %tmp_4_85 = fmul float %a_load_86, %b_load_86
  %tmp_5_85 = fadd float %tmp_5_84, %tmp_4_85
  %a_load_87 = load float* %a_addr_87, align 4
  %b_load_87 = load float* %b_addr_87, align 4
  %tmp_4_86 = fmul float %a_load_87, %b_load_87
  %tmp_5_86 = fadd float %tmp_5_85, %tmp_4_86
  %a_load_88 = load float* %a_addr_88, align 4
  %b_load_88 = load float* %b_addr_88, align 4
  %tmp_4_87 = fmul float %a_load_88, %b_load_88
  %tmp_5_87 = fadd float %tmp_5_86, %tmp_4_87
  %a_load_89 = load float* %a_addr_89, align 4
  %b_load_89 = load float* %b_addr_89, align 4
  %tmp_4_88 = fmul float %a_load_89, %b_load_89
  %tmp_5_88 = fadd float %tmp_5_87, %tmp_4_88
  %a_load_90 = load float* %a_addr_90, align 4
  %b_load_90 = load float* %b_addr_90, align 4
  %tmp_4_89 = fmul float %a_load_90, %b_load_90
  %tmp_5_89 = fadd float %tmp_5_88, %tmp_4_89
  %a_load_91 = load float* %a_addr_91, align 4
  %b_load_91 = load float* %b_addr_91, align 4
  %tmp_4_90 = fmul float %a_load_91, %b_load_91
  %tmp_5_90 = fadd float %tmp_5_89, %tmp_4_90
  %a_load_92 = load float* %a_addr_92, align 4
  %b_load_92 = load float* %b_addr_92, align 4
  %tmp_4_91 = fmul float %a_load_92, %b_load_92
  %tmp_5_91 = fadd float %tmp_5_90, %tmp_4_91
  %a_load_93 = load float* %a_addr_93, align 4
  %b_load_93 = load float* %b_addr_93, align 4
  %tmp_4_92 = fmul float %a_load_93, %b_load_93
  %tmp_5_92 = fadd float %tmp_5_91, %tmp_4_92
  %a_load_94 = load float* %a_addr_94, align 4
  %b_load_94 = load float* %b_addr_94, align 4
  %tmp_4_93 = fmul float %a_load_94, %b_load_94
  %tmp_5_93 = fadd float %tmp_5_92, %tmp_4_93
  %a_load_95 = load float* %a_addr_95, align 4
  %b_load_95 = load float* %b_addr_95, align 4
  %tmp_4_94 = fmul float %a_load_95, %b_load_95
  %tmp_5_94 = fadd float %tmp_5_93, %tmp_4_94
  %a_load_96 = load float* %a_addr_96, align 4
  %b_load_96 = load float* %b_addr_96, align 4
  %tmp_4_95 = fmul float %a_load_96, %b_load_96
  %tmp_5_95 = fadd float %tmp_5_94, %tmp_4_95
  %a_load_97 = load float* %a_addr_97, align 4
  %b_load_97 = load float* %b_addr_97, align 4
  %tmp_4_96 = fmul float %a_load_97, %b_load_97
  %tmp_5_96 = fadd float %tmp_5_95, %tmp_4_96
  %a_load_98 = load float* %a_addr_98, align 4
  %b_load_98 = load float* %b_addr_98, align 4
  %tmp_4_97 = fmul float %a_load_98, %b_load_98
  %tmp_5_97 = fadd float %tmp_5_96, %tmp_4_97
  %a_load_99 = load float* %a_addr_99, align 4
  %b_load_99 = load float* %b_addr_99, align 4
  %tmp_4_98 = fmul float %a_load_99, %b_load_99
  %tmp_5_98 = fadd float %tmp_5_97, %tmp_4_98
  store float %tmp_5_98, float* %out_addr, align 4
  %empty_2 = call i32 (...)* @_ssdm_op_SpecRegionEnd([16 x i8]* @p_str, i32 %tmp_1) nounwind
  br label %1

; <label>:3                                       ; preds = %1
  ret void
}

declare void @llvm.dbg.value(metadata, i64, metadata) nounwind readnone

define weak void @_ssdm_op_SpecTopModule(...) {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecRegionEnd(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecRegionBegin(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecPipeline(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecLoopTripCount(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecLoopName(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecBitsMap(...) {
entry:
  ret void
}

declare void @_GLOBAL__I_a() nounwind section ".text.startup"

!opencl.kernels = !{!0}
!hls.encrypted.func = !{}
!llvm.map.gv = !{!7}

!0 = metadata !{null, metadata !1, metadata !2, metadata !3, metadata !4, metadata !5, metadata !6}
!1 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 1, i32 1}
!2 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none", metadata !"none"}
!3 = metadata !{metadata !"kernel_arg_type", metadata !"float [100]*", metadata !"float [100]*", metadata !"float*"}
!4 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !"", metadata !""}
!5 = metadata !{metadata !"kernel_arg_name", metadata !"a", metadata !"b", metadata !"out"}
!6 = metadata !{metadata !"reqd_work_group_size", i32 1, i32 1, i32 1}
!7 = metadata !{metadata !8, [1 x i32]* @llvm_global_ctors_0}
!8 = metadata !{metadata !9}
!9 = metadata !{i32 0, i32 31, metadata !10}
!10 = metadata !{metadata !11}
!11 = metadata !{metadata !"llvm.global_ctors.0", metadata !12, metadata !"", i32 0, i32 31}
!12 = metadata !{metadata !13}
!13 = metadata !{i32 0, i32 0, i32 1}
!14 = metadata !{metadata !15}
!15 = metadata !{i32 0, i32 31, metadata !16}
!16 = metadata !{metadata !17}
!17 = metadata !{metadata !"a", metadata !18, metadata !"float", i32 0, i32 31}
!18 = metadata !{metadata !19, metadata !19}
!19 = metadata !{i32 0, i32 99, i32 1}
!20 = metadata !{metadata !21}
!21 = metadata !{i32 0, i32 31, metadata !22}
!22 = metadata !{metadata !23}
!23 = metadata !{metadata !"b", metadata !18, metadata !"float", i32 0, i32 31}
!24 = metadata !{metadata !25}
!25 = metadata !{i32 0, i32 31, metadata !26}
!26 = metadata !{metadata !27}
!27 = metadata !{metadata !"out", metadata !28, metadata !"float", i32 0, i32 31}
!28 = metadata !{metadata !19}
